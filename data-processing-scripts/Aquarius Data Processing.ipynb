{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21599b59-758a-4f10-9677-340465d599dd",
   "metadata": {},
   "source": [
    "# MCM LTER Aquarius Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed767381-1e68-4a6d-a14f-44fbb5fa4d09",
   "metadata": {},
   "source": [
    "This script was created by Jared Collins on 6/26/2025 to be used by the MCM LTER stream team as an easy way to merge and organize data downloaded from Aquarius. The original processing code was done in R. The hope is this python script will be easier to use and more intuitive, allowing users to easily convert data files into publishable forms. In the future, it may need to be edited/changed to reflect changes in data collection strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255652bf-31a5-4f94-a337-de2bf71ee61f",
   "metadata": {},
   "source": [
    "## Importing Packages + Setting Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34067f5e-9faa-4f19-b3be-f12f091e8593",
   "metadata": {},
   "source": [
    "It is very important that the computer being used for processing contains the proper packages, paths, and names for the data files that will be used. **The script expects the data files from Aquarius to be stored in the downloads folder with no edits made to the name of the file. Please ensure that this is the case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c504ea58-138e-4af8-add7-80c6aa194ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376bdc95-2aeb-42a4-ae77-1378ad584fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads folder: C:/Users/jared/Downloads\n"
     ]
    }
   ],
   "source": [
    "home = Path.home()\n",
    "downloads_path = home / \"Downloads\"\n",
    "downloads_path = downloads_path.as_posix()\n",
    "print(\"Downloads folder:\", downloads_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab24e3-fc13-456d-9295-597e1fc464af",
   "metadata": {},
   "source": [
    "## Specifying Data (EDIT THIS SECTION ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2a5ee-9463-48e9-8ea5-f668d0efc5e7",
   "metadata": {},
   "source": [
    "In order for this script to work properly, you will need to input necessary information about the files that you are hoping to publish:\n",
    "- Stream ID: Acceptable formats are B3, B5, C1, F1, F2, F3, F5, F6, F7, F8, F9, F10, H1, M1, M2, Onyx_LWRT, Onyx_Vanda\n",
    "- Season: Separate seasons into A and B data depending on what portion of the data you are working on; will only impact how datafile is saved\n",
    "- Date: The first day of the data file, written in \"YYYYMMDD\" format\n",
    "\n",
    "**Edit the following cell with the information above. If done correctly, this is the only cell you will have to edit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb349cb9-d414-4cf2-a729-7c6da3931b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamid = 'F1'\n",
    "season = '2425A'\n",
    "date = '20241203'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103342d6-6e83-4f74-a7d3-a97fd9fab978",
   "metadata": {},
   "source": [
    "## Organizing Data and Publishing CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67971474-8af3-4286-b5a2-c856d9ac5553",
   "metadata": {},
   "source": [
    "The following cell contains some lists for the script to detect which stream is being worked on and how to fill in the data appropriately. These should never have to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "415f1a12-f769-446c-b2fc-0f697b66e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamid_map = {\n",
    "    'B3': 'lawson_b3',\n",
    "    'B5': 'bohner_b5',\n",
    "    'C1': 'common_c1',\n",
    "    'F1': 'canada_f1',\n",
    "    'F2': 'huey_f2',\n",
    "    'F3': 'lostseal_f3',\n",
    "    'F5': 'aiken_f5',\n",
    "    'F6': 'vonguerard_f6',\n",
    "    'F7': 'harnish_f7',\n",
    "    'F8': 'crescent_f8',\n",
    "    'F9': 'green_f9',\n",
    "    'F10': 'delta_f10',\n",
    "    'M1': 'adams_m1',\n",
    "    'M2': 'miers_m2',\n",
    "    'Onyx_LWRT': 'onyx_lwright',\n",
    "    'Onyx_Vanda': 'onyx_vnda'}\n",
    "\n",
    "grade_map = {\n",
    "    '1': 'unverified',\n",
    "    '11': 'poor',\n",
    "    '21': 'fair',\n",
    "    '31': 'good',\n",
    "    '41': 'excellent'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46235f19-d4e2-4018-911c-fbfc632a3cc2",
   "metadata": {},
   "source": [
    "The next cell deals with calling the data files downloaded from Aquarius that we will be combining in this script. So long as the file is in the downloads folder of your computer and you did not change the name from aquarius, this cell should work perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9fcd97-fd99-4921-8ee5-1c4bc736d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = pd.read_csv(f'{downloads_path}/Discharge.Metric@{streamid}.{date}.csv', skiprows=14)\n",
    "temp = pd.read_csv(f'{downloads_path}/Water_Temp.Working@{streamid}.{date}.csv', skiprows=14)\n",
    "spc = pd.read_csv(f'{downloads_path}/Sp_Cond.Working@{streamid}.{date}.csv', skiprows=14)\n",
    "dosat = pd.read_csv(f'{downloads_path}/Dis_Oxygen_Sat.Working@{streamid}.{date}.csv', skiprows=14)\n",
    "doconc = pd.read_csv(f'{downloads_path}/O2_(Dis).Working@{streamid}.{date}.csv', skiprows=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5e2a3-1e6f-4be1-a82c-4cd0f1e58472",
   "metadata": {},
   "source": [
    "The following cell deals with creating the dataframe that will contain all of the data specified and ready for publishing, as well as generating the CSV file output. **It will publish this file to your downloads folder, so be sure to move it to the appropriate Stream Team folder once done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "105181a4-21f5-46d2-ae4b-a8a2a5f93614",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_file = pd.DataFrame()\n",
    "subm_file['DATASET_CODE'] = ['DSCRT_STRM_GAGE'] * len(dis)\n",
    "subm_file['STRM_GAGE_ID'] = [streamid_map[streamid]] * len(dis)\n",
    "subm_file['DATE_TIME'] = dis['Timestamp (UTC+13:00)']\n",
    "subm_file['DISCHARGE_RATE'] = dis['Value']\n",
    "subm_file['DISCHARGE_QLTY'] = dis['Grade'].astype(str).map(grade_map)\n",
    "subm_file['WATER_TEMP'] = temp['Value']\n",
    "subm_file['WATER_TEMP_QLTY'] = temp['Grade'].astype(str).map(grade_map)\n",
    "subm_file['SPECIFIC_CONDUCTANCE'] = spc['Value']\n",
    "subm_file['SPECIFIC_CONDUCTANCE_QLTY'] = spc['Grade'].astype(str).map(grade_map)\n",
    "subm_file['DIS_OXYGEN_SAT'] = dosat['Value']\n",
    "subm_file['DIS_OXYGEN_SAT_QLTY'] = dosat['Grade'].astype(str).map(grade_map)\n",
    "subm_file['DIS_OXYGEN_CONC'] = doconc['Value']\n",
    "subm_file['DIS_OXYGEN_CONC_QLTY'] = doconc['Grade'].astype(str).map(grade_map)\n",
    "subm_file.to_csv(f'{downloads_path}/{streamid}_{season}_SUBM.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
